{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import re\n",
    "from pathlib import PurePath\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-defined parameters\n",
    "\n",
    "\n",
    "- **threshold**: Represents the distance parameter used by the wind transpose model (1/2/4 times the experimental area radius).\n",
    "- **duration**: Denotes the minimum event length in Stanford Defined Events that should be disregarded (30/60/120 seconds).\n",
    "\n",
    "- **short_stack**: which means whether we only conside short head stack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Parameters: \n",
      "ignore_duration:  60\n",
      "threshold:  2\n",
      "short_stack:  0\n"
     ]
    }
   ],
   "source": [
    "# ignore_duration = 30 # Ignore events with a duration of less than 30 seconds\n",
    "duration = 60 # Ignore events with a duration of less than 1 minute\n",
    "# ignore_duration = 120 # Ignore events with a duration of less than 2 minutes\n",
    "\n",
    "# threshold = 1\n",
    "threshold = 2\n",
    "# threshold = 4\n",
    "\n",
    "short_stack = 0\n",
    "# short_stack = 1\n",
    "\n",
    "\n",
    "print(\"Input Parameters: \")\n",
    "print(\"ignore_duration: \", duration)\n",
    "print(\"threshold: \", threshold)\n",
    "print(\"short_stack: \", short_stack)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data\n",
    "\n",
    "## 1.1 Stanford-defined events dataset\n",
    "\n",
    "- Stanford-Defined Dataset (Camera-Based): Categorized with Positive and Negative labels\n",
    "- Stanford-Defined Dataset (Sensor-Based): Categorized as Positive or Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for camera-based stanford-defined events...\n",
      "Loaded data for camera-based stanford-defined events\n",
      "Loading data for sensor-based stanford-defined events...\n",
      "Loaded data for sensor-based stanford-defined events\n"
     ]
    }
   ],
   "source": [
    "# 1. Stanford-Defined Events Dataset(Camera-based)\n",
    "# which saved in the file: assets/events/PN/candidate_event_duration=60xseconds_[P/N/NA].csv\n",
    "\n",
    "print(\"Loading data for camera-based stanford-defined events...\")\n",
    "camera_based_stanford_defined_events_p = pd.read_csv(\n",
    "    f'../../assets/events_PN/candidate_event_duration={duration}xseconds_P.csv')\n",
    "camera_based_stanford_defined_events_p[\"ManualDate\"] = \\\n",
    "    camera_based_stanford_defined_events_p[\"ManualStartDateTime\"].map(lambda x: pd.to_datetime(x).date())\n",
    "\n",
    "camera_based_stanford_defined_events_n = pd.read_csv(\n",
    "    f'../../assets/events_PN/candidate_event_duration={duration}xseconds_N.csv')\n",
    "camera_based_stanford_defined_events_n[\"ManualDate\"] = \\\n",
    "    camera_based_stanford_defined_events_n[\"ManualStartDateTime\"].map(lambda x: pd.to_datetime(x).date())\n",
    "camera_based_stanford_defined_events_na = pd.read_csv(\n",
    "    f'../../assets/events_PN/candidate_event_duration={duration}xseconds_NA.csv')\n",
    "camera_based_stanford_defined_events_na[\"ManualDate\"] = \\\n",
    "    camera_based_stanford_defined_events_na[\"ManualStartDateTime\"].map(lambda x: pd.to_datetime(x).date())\n",
    "\n",
    "\n",
    "print(\"Loaded data for camera-based stanford-defined events\")\n",
    "\n",
    "# 2. Stanford-Defined Events Dataset(Sensor-based)\n",
    "# which saved in the file: assets/events/PN/true_event_threshold=2xradius_duration=60xseconds_[P/N/NA].csv\n",
    "\n",
    "print(\"Loading data for sensor-based stanford-defined events...\")\n",
    "sensor_based_stanford_defined_events_p = pd.read_csv(\n",
    "    f'../../assets/events_PN/true_event_threshold={threshold}xradius_duration={duration}xseconds_P.csv')\n",
    "sensor_based_stanford_defined_events_p[\"ManualDate\"] = \\\n",
    "    sensor_based_stanford_defined_events_p[\"ManualStartDateTime\"].map(lambda x: pd.to_datetime(x).date())\n",
    "sensor_based_stanford_defined_events_n = pd.read_csv(\n",
    "    f'../../assets/events_PN/true_event_threshold={threshold}xradius_duration={duration}xseconds_N.csv')\n",
    "sensor_based_stanford_defined_events_n[\"ManualDate\"] = \\\n",
    "    sensor_based_stanford_defined_events_n[\"ManualStartDateTime\"].map(lambda x: pd.to_datetime(x).date())\n",
    "sensor_based_stanford_defined_events_na = pd.read_csv(\n",
    "    f'../../assets/events_PN/true_event_threshold={threshold}xradius_duration={duration}xseconds_NA.csv')\n",
    "sensor_based_stanford_defined_events_na[\"ManualDate\"] = \\\n",
    "    sensor_based_stanford_defined_events_na[\"ManualStartDateTime\"].map(lambda x: pd.to_datetime(x).date())\n",
    "print(\"Loaded data for sensor-based stanford-defined events\")\n",
    "\n",
    "\n",
    "if short_stack:\n",
    "    camera_based_stanford_defined_events_p = camera_based_stanford_defined_events_p[(camera_based_stanford_defined_events_p[\"ManualDate\"] == pd.to_datetime(\"2022-10-31\").date()) | \n",
    "                      ((camera_based_stanford_defined_events_p[\"ManualDate\"] >= pd.to_datetime(\"2022-11-15\").date()) & (camera_based_stanford_defined_events_p[\"ManualDate\"] <= pd.to_datetime(\"2022-11-30\").date()))]\n",
    "    camera_based_stanford_defined_events_n = camera_based_stanford_defined_events_n.append(camera_based_stanford_defined_events_n[(camera_based_stanford_defined_events_n[\"ManualDate\"] == pd.to_datetime(\"2022-10-31\").date()) |\n",
    "                        ((camera_based_stanford_defined_events_n[\"ManualDate\"] >= pd.to_datetime(\"2022-11-15\").date()) & (camera_based_stanford_defined_events_n[\"ManualDate\"] <= pd.to_datetime(\"2022-11-30\").date()))])\n",
    "    camera_based_stanford_defined_events_na = camera_based_stanford_defined_events_na.append(camera_based_stanford_defined_events_na[(camera_based_stanford_defined_events_na[\"ManualDate\"] == pd.to_datetime(\"2022-10-31\").date()) |\n",
    "                        ((camera_based_stanford_defined_events_na[\"ManualDate\"] >= pd.to_datetime(\"2022-11-15\").date()) & (camera_based_stanford_defined_events_na[\"ManualDate\"] <= pd.to_datetime(\"2022-11-30\").date()))])\n",
    "    camera_based_stanford_defined_events_p.reset_index(drop=True, inplace=True)\n",
    "    camera_based_stanford_defined_events_n.reset_index(drop=True, inplace=True)\n",
    "    camera_based_stanford_defined_events_na.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "\n",
    "    sensor_based_stanford_defined_events_p = sensor_based_stanford_defined_events_p[(sensor_based_stanford_defined_events_p[\"ManualDate\"] == pd.to_datetime(\"2022-10-31\").date()) |\n",
    "                        ((sensor_based_stanford_defined_events_p[\"ManualDate\"] >= pd.to_datetime(\"2022-11-15\").date()) & (sensor_based_stanford_defined_events_p[\"ManualDate\"] <= pd.to_datetime(\"2022-11-30\").date()))]\n",
    "    sensor_based_stanford_defined_events_n = sensor_based_stanford_defined_events_n.append(sensor_based_stanford_defined_events_n[(sensor_based_stanford_defined_events_n[\"ManualDate\"] == pd.to_datetime(\"2022-10-31\").date()) |\n",
    "                        ((sensor_based_stanford_defined_events_n[\"ManualDate\"] >= pd.to_datetime(\"2022-11-15\").date()) & (sensor_based_stanford_defined_events_n[\"ManualDate\"] <= pd.to_datetime(\"2022-11-30\").date()))])\n",
    "    sensor_based_stanford_defined_events_na = sensor_based_stanford_defined_events_na.append(sensor_based_stanford_defined_events_na[(sensor_based_stanford_defined_events_na[\"ManualDate\"] == pd.to_datetime(\"2022-10-31\").date()) |\n",
    "                        ((sensor_based_stanford_defined_events_na[\"ManualDate\"] >= pd.to_datetime(\"2022-11-15\").date()) & (sensor_based_stanford_defined_events_na[\"ManualDate\"] <= pd.to_datetime(\"2022-11-30\").date()))])\n",
    "    sensor_based_stanford_defined_events_p.reset_index(drop=True, inplace=True)\n",
    "    sensor_based_stanford_defined_events_n.reset_index(drop=True, inplace=True)\n",
    "    sensor_based_stanford_defined_events_na.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Team-defined events dataset\n",
    "\n",
    "- Team-Defined Events Dataset(Camera-based): Categorized with Positive, Negative, and N/A labels for camera-based operators: Andium, Oiler, Kuva\n",
    "- Team-Defined Events Dataset(Sensor-based): Categorized with Positive, Negative, and N/A labels for sensor-based operators: Canary, Ecoteco, Qube, Sensirion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for sensor: Andium\tDone.\n",
      "Loading data for sensor: Canary\tDone.\n",
      "Loading data for sensor: Ecoteco\tDone.\n",
      "Loading data for sensor: Kuva\tDone.\n",
      "Loading data for sensor: Oiler\tDone.\n",
      "Loading data for sensor: Qube\tDone.\n",
      "Loading data for sensor: Sensirion\tDone.\n",
      "Loading data for sensor: Soofie\tDone.\n"
     ]
    }
   ],
   "source": [
    "# 3. Team-Defined Events Dataset\n",
    "# which stored in the file: assets/sensor_data/[sensor_name]_caliddata.csv\n",
    "\n",
    "sensor_names = [\n",
    "    \"Andium\", \n",
    "    \"Canary\",\n",
    "    \"Ecoteco\",\n",
    "    \"Kuva\",\n",
    "    \"Oiler\",\n",
    "    \"Qube\",\n",
    "    \"Sensirion\",\n",
    "    \"Soofie\"\n",
    "]\n",
    "\n",
    "camera_based_sensor_names = [\n",
    "    \"Andium\", \n",
    "    \"Kuva\",\n",
    "    \"Oiler\"\n",
    "]\n",
    "sensor_based_sensor_names = [\n",
    "    \"Canary\",\n",
    "    \"Ecoteco\",\n",
    "    \"Qube\",\n",
    "    \"Sensirion\",\n",
    "    \"Soofie\"\n",
    "]\n",
    "\n",
    "df_team_defined_events = {}\n",
    "for sn in sensor_names:\n",
    "    print(\"Loading data for sensor: \" + sn, end=\"\\t\")\n",
    "    df_team_defined_events[sn] = pd.read_csv(\n",
    "        '../../assets/sensor_data/' + sn + '_validdata.csv', \n",
    "        parse_dates=['EmissionStartDateTime', \"EmissionEndDateTime\"]\n",
    "    )[[\"EmissionStartDateTime\", \"EmissionEndDateTime\", \"ReportLabel\"]]\n",
    "    print(\"Done.\")\n",
    "\n",
    "    if short_stack:\n",
    "        df_team_defined_events[sn][\"ReportDate\"] = df_team_defined_events[sn][\"EmissionStartDateTime\"].map(lambda x: pd.to_datetime(x).date())\n",
    "        df_team_defined_events[sn] = df_team_defined_events[sn][(df_team_defined_events[sn][\"ReportDate\"] == pd.to_datetime(\"2022-10-31\").date()) |\n",
    "                        ((df_team_defined_events[sn][\"ReportDate\"] >= pd.to_datetime(\"2022-11-15\").date()) & (df_team_defined_events[sn][\"ReportDate\"] <= pd.to_datetime(\"2022-11-30\").date()))]\n",
    "        df_team_defined_events[sn].reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Continuous Time Series: Stanford Defined Time Series\n",
    "1. Time Range: 2022-10-10 00:00:00 to 2022-11-30 23:59:59\n",
    "2. Initial Category: All timestamps set to N/A\n",
    "3. Final Assignment: Timestamps categorized as Positive, Negative, or remain N/A\n",
    "4. For each event in the team-defined events dataset, find its start time, end time and label, For the continuous time series: Assign timestamps that fall within the current event to the label of the current event "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating camera-based stanford-defined time series...\n",
      "Generating camera-based stanford-defined time series for Positive events\tDone.\n",
      "Generating camera-based stanford-defined time series for Negative events\tDone.\n"
     ]
    }
   ],
   "source": [
    "# camera-based stanford-defined time series\n",
    "camera_based_stanford_defined_events_p[\"ManualStartDateTime\"] = pd.to_datetime(\n",
    "    camera_based_stanford_defined_events_p[\"ManualStartDateTime\"])\n",
    "camera_based_stanford_defined_events_p[\"ManualEndDateTime\"] = pd.to_datetime(\n",
    "    camera_based_stanford_defined_events_p[\"ManualEndDateTime\"])\n",
    "camera_based_stanford_defined_events_n[\"ManualStartDateTime\"] = pd.to_datetime(\n",
    "    camera_based_stanford_defined_events_n[\"ManualStartDateTime\"])\n",
    "camera_based_stanford_defined_events_n[\"ManualEndDateTime\"] = pd.to_datetime(\n",
    "    camera_based_stanford_defined_events_n[\"ManualEndDateTime\"])\n",
    "camera_based_stanford_defined_events_na[\"ManualStartDateTime\"] = pd.to_datetime(\n",
    "    camera_based_stanford_defined_events_na[\"ManualStartDateTime\"])\n",
    "camera_based_stanford_defined_events_na[\"ManualEndDateTime\"] = pd.to_datetime(\n",
    "    camera_based_stanford_defined_events_na[\"ManualEndDateTime\"])\n",
    "\n",
    "# initialize the dataframe for camera-based stanford-defined time series, Datetime (UTC) from 2022-10-10 00:00:00 to 2022-11-30 23:59:59\n",
    "# TrueLabel is set to NA defaultly\n",
    "camera_based_stanford_defined_time_series = pd.DataFrame(columns=[\"Datetime (UTC)\", \"TrueLabel\"])\n",
    "camera_based_stanford_defined_time_series[\"Datetime (UTC)\"] = pd.date_range(\n",
    "    start=\"2022-10-10 00:00:00\", end=\"2022-11-30 23:59:59\", freq=\"S\")\n",
    "camera_based_stanford_defined_time_series[\"TrueLabel\"] = \"NA\"\n",
    "\n",
    "\n",
    "print(\"Generating camera-based stanford-defined time series...\")\n",
    "print(\"Generating camera-based stanford-defined time series for Positive events\", end=\"\\t\")\n",
    "for i in range(camera_based_stanford_defined_events_p.shape[0]):\n",
    "    start = camera_based_stanford_defined_events_p.iloc[i][\"ManualStartDateTime\"]\n",
    "    end = camera_based_stanford_defined_events_p.iloc[i][\"ManualEndDateTime\"]\n",
    "    camera_based_stanford_defined_time_series.loc[\n",
    "        (camera_based_stanford_defined_time_series[\"Datetime (UTC)\"] >= start) & \n",
    "        (camera_based_stanford_defined_time_series[\"Datetime (UTC)\"] <= end), \n",
    "        \"TrueLabel\"] = \"P\"\n",
    "print(\"Done.\")\n",
    "print(\"Generating camera-based stanford-defined time series for Negative events\", end=\"\\t\")\n",
    "for i in range(camera_based_stanford_defined_events_n.shape[0]):\n",
    "    start = camera_based_stanford_defined_events_n.iloc[i][\"ManualStartDateTime\"]\n",
    "    end = camera_based_stanford_defined_events_n.iloc[i][\"ManualEndDateTime\"]\n",
    "    camera_based_stanford_defined_time_series.loc[\n",
    "        (camera_based_stanford_defined_time_series[\"Datetime (UTC)\"] >= start) & \n",
    "        (camera_based_stanford_defined_time_series[\"Datetime (UTC)\"] <= end), \n",
    "        \"TrueLabel\"] = \"N\"\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sensor-based stanford-defined time series...\n",
      "Generating sensor-based stanford-defined time series for Positive events\tDone.\n",
      "Generating sensor-based stanford-defined time series for Negative events\tDone.\n"
     ]
    }
   ],
   "source": [
    "# sensor-based stanford-defined time series\n",
    "sensor_based_stanford_defined_events_p[\"ManualStartDateTime\"] = pd.to_datetime(\n",
    "    sensor_based_stanford_defined_events_p[\"ManualStartDateTime\"])\n",
    "sensor_based_stanford_defined_events_p[\"ManualEndDateTime\"] = pd.to_datetime(\n",
    "    sensor_based_stanford_defined_events_p[\"ManualEndDateTime\"])\n",
    "sensor_based_stanford_defined_events_n[\"ManualStartDateTime\"] = pd.to_datetime(\n",
    "    sensor_based_stanford_defined_events_n[\"ManualStartDateTime\"])\n",
    "sensor_based_stanford_defined_events_n[\"ManualEndDateTime\"] = pd.to_datetime(\n",
    "    sensor_based_stanford_defined_events_n[\"ManualEndDateTime\"])\n",
    "sensor_based_stanford_defined_events_na[\"ManualStartDateTime\"] = pd.to_datetime(\n",
    "    sensor_based_stanford_defined_events_na[\"ManualStartDateTime\"])\n",
    "sensor_based_stanford_defined_events_na[\"ManualEndDateTime\"] = pd.to_datetime(\n",
    "    sensor_based_stanford_defined_events_na[\"ManualEndDateTime\"])\n",
    "\n",
    "\n",
    "# initialize the dataframe for sensor-based stanford-defined time series, Datetime (UTC) from 2022-10-10 00:00:00 to 2022-11-30 23:59:59\n",
    "# TrueLabel is set to NA defaultly\n",
    "sensor_based_stanford_defined_time_series = pd.DataFrame(columns=[\"Datetime (UTC)\", \"TrueLabel\"])\n",
    "sensor_based_stanford_defined_time_series[\"Datetime (UTC)\"] = pd.date_range(\n",
    "    start=\"2022-10-10 00:00:00\", end=\"2022-11-30 23:59:59\", freq=\"S\")\n",
    "sensor_based_stanford_defined_time_series[\"TrueLabel\"] = \"NA\"\n",
    "\n",
    "print(\"Generating sensor-based stanford-defined time series...\")\n",
    "print(\"Generating sensor-based stanford-defined time series for Positive events\", end=\"\\t\")\n",
    "for i in range(sensor_based_stanford_defined_events_p.shape[0]):\n",
    "    start = sensor_based_stanford_defined_events_p.iloc[i][\"ManualStartDateTime\"]\n",
    "    end = sensor_based_stanford_defined_events_p.iloc[i][\"ManualEndDateTime\"]\n",
    "    sensor_based_stanford_defined_time_series.loc[\n",
    "        (sensor_based_stanford_defined_time_series[\"Datetime (UTC)\"] >= start) & \n",
    "        (sensor_based_stanford_defined_time_series[\"Datetime (UTC)\"] <= end), \n",
    "        \"TrueLabel\"] = \"P\"\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Generating sensor-based stanford-defined time series for Negative events\", end=\"\\t\")\n",
    "for i in range(sensor_based_stanford_defined_events_n.shape[0]):\n",
    "    start = sensor_based_stanford_defined_events_n.iloc[i][\"ManualStartDateTime\"]\n",
    "    end = sensor_based_stanford_defined_events_n.iloc[i][\"ManualEndDateTime\"]\n",
    "    sensor_based_stanford_defined_time_series.loc[\n",
    "        (sensor_based_stanford_defined_time_series[\"Datetime (UTC)\"] >= start) & \n",
    "        (sensor_based_stanford_defined_time_series[\"Datetime (UTC)\"] <= end), \n",
    "        \"TrueLabel\"] = \"N\"\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Continuous Time Series: Team Defined Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating team-defined time series for sensor: Andium\tDone.\n",
      "Generating team-defined time series for sensor: Canary\tDone.\n",
      "Generating team-defined time series for sensor: Ecoteco\tDone.\n",
      "Generating team-defined time series for sensor: Kuva\tDone.\n",
      "Generating team-defined time series for sensor: Oiler\tDone.\n",
      "Generating team-defined time series for sensor: Qube\tDone.\n",
      "Generating team-defined time series for sensor: Sensirion\tDone.\n",
      "Generating team-defined time series for sensor: Soofie\tDone.\n"
     ]
    }
   ],
   "source": [
    "team_defined_time_series = {}\n",
    "\n",
    "for sn in sensor_names:\n",
    "\n",
    "    print(\"Generating team-defined time series for sensor: \" + sn, end=\"\\t\")\n",
    "    df_team_defined_events[sn][\"EmissionStartDateTime\"] = pd.to_datetime(\n",
    "        df_team_defined_events[sn][\"EmissionStartDateTime\"])\n",
    "    df_team_defined_events[sn][\"EmissionEndDateTime\"] = pd.to_datetime(\n",
    "        df_team_defined_events[sn][\"EmissionEndDateTime\"])\n",
    "    \n",
    "    current_team_defined_time_series = pd.DataFrame(columns=[\"Datetime (UTC)\", \"TrueLabel\"])\n",
    "    current_team_defined_time_series[\"Datetime (UTC)\"] = pd.date_range(\n",
    "        start=\"2022-10-10 00:00:00\", end=\"2022-11-30 23:59:59\", freq=\"S\")\n",
    "    current_team_defined_time_series[\"ReportLabel\"] = \"NA\"\n",
    "\n",
    "\n",
    "    for i in range(df_team_defined_events[sn].shape[0]):\n",
    "        start = df_team_defined_events[sn].iloc[i][\"EmissionStartDateTime\"]\n",
    "        end = df_team_defined_events[sn].iloc[i][\"EmissionEndDateTime\"]\n",
    "        current_team_defined_time_series.loc[\n",
    "            (current_team_defined_time_series[\"Datetime (UTC)\"] >= start) & \n",
    "            (current_team_defined_time_series[\"Datetime (UTC)\"] <= end), \n",
    "            \"ReportLabel\"] = df_team_defined_events[sn].iloc[i][\"ReportLabel\"]\n",
    "    \n",
    "    team_defined_time_series[sn] = current_team_defined_time_series\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Merge Continues Time-series\n",
    "\n",
    "Merge Stanford and Team-Defined Time Series: Create a continuous timeline from 2022-10-10 00:00:00 to 2022-11-30 23:59:59. Each timestamp has two attributes:\n",
    "- GT (Ground Truth): Derived from the Stanford-defined category\n",
    "- Pred (Prediction): Derived from the team-defined category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining time series for sensor: Andium\tDone.\n",
      "Combining time series for sensor: Canary\tDone.\n",
      "Combining time series for sensor: Ecoteco\tDone.\n",
      "Combining time series for sensor: Kuva\tDone.\n",
      "Combining time series for sensor: Oiler\tDone.\n",
      "Combining time series for sensor: Qube\tDone.\n",
      "Combining time series for sensor: Sensirion\tDone.\n",
      "Combining time series for sensor: Soofie\tDone.\n"
     ]
    }
   ],
   "source": [
    "combine_time_series = {}\n",
    "\n",
    "for sn in sensor_names:\n",
    "    print(\"Combining time series for sensor: \" + sn, end=\"\\t\")\n",
    "    if sn in camera_based_sensor_names:\n",
    "        stanford_defined_time_series = camera_based_stanford_defined_time_series\n",
    "    else:\n",
    "        stanford_defined_time_series = sensor_based_stanford_defined_time_series\n",
    "\n",
    "    # Combine the team-defined time series and stanford-defined time series\n",
    "    combine_time_series[sn] = pd.DataFrame(columns=[\"Datetime (UTC)\", \"GT\", \"Pred\"])\n",
    "    combine_time_series[sn][\"Datetime (UTC)\"] = stanford_defined_time_series[\"Datetime (UTC)\"]\n",
    "    combine_time_series[sn][\"GT\"] = stanford_defined_time_series[\"TrueLabel\"]\n",
    "    combine_time_series[sn][\"Pred\"] = team_defined_time_series[sn][\"ReportLabel\"]\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculation of time-based metrics:\n",
    "- Total sample size: The number of timestamps in the time-based sequence where GT is not N/A and Pred is not N/A, marked as Ntotal\n",
    "- TP: The number of timestamps in the time-based sequence where GT is P and Pred is P, marked as NTP\n",
    "- FP: The number of timestamps in the time-based sequence where GT is N and Pred is P, marked as NFP\n",
    "- TN: The number of timestamps in the time-based sequence where GT is N and Pred is N, marked as NTN\n",
    "- FN: The number of timestamps in the time-based sequence where GT is P and Pred is N, marked as NFN\n",
    "- TP(%): NTP / Ntotal * 100 \n",
    "- FP(%): NFP / Ntotal * 100 \n",
    "- FN(%): NFN / Ntotal * 100 \n",
    "- TN(%): NFN / Ntotal * 100 \n",
    "- FPR(%): NFP / (NFP +NTN) * 100\n",
    "- TNR(%): NTN / (NFP +NTN) * 100\n",
    "- TPR(%): NTP / (NTP +NFN) * 100\n",
    "- FNR(%): NFN / (NFN +NTP) * 100\n",
    "- Accuracy(%): (NTP + NTN) / Ntotal * 100\n",
    "- Precision(%): NTP/(NFP +NTP) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics...\n",
      "Calculating metrics for sensor: Andium\n",
      "\tTP, FP, FN, TN:  191798 4379 141025 2791778\n",
      "\tTP(%), FP(%), FN(%), TN(%):  6.129729176920274 0.13994975998568224 4.507059808627732 89.22326125446631\n",
      "\tFPR(%), TPR(%), TNR(%), FNR(%):  0.15660780135021032 57.62762789831232 99.8433921986498 42.37237210168768\n",
      "\tAccuracy(%), Precision(%):  95.35299043138659 97.7678321107979\n",
      "Done.\n",
      "Calculating metrics for sensor: Canary\n",
      "\tTP, FP, FN, TN:  139394 19236 5487 1190630\n",
      "\tTP(%), FP(%), FN(%), TN(%):  10.289301249606014 1.41989611344406 0.40502027315801403 87.8857823637919\n",
      "\tFPR(%), TPR(%), TNR(%), FNR(%):  1.58992814080237 96.2127539152822 98.41007185919763 3.7872460847178027\n",
      "\tAccuracy(%), Precision(%):  98.17508361339793 87.87366828468764\n",
      "Done.\n",
      "Calculating metrics for sensor: Ecoteco\n",
      "\tTP, FP, FN, TN:  25948 22202 241302 2349707\n",
      "\tTP(%), FP(%), FN(%), TN(%):  0.9831919941163074 0.8412528384989308 9.143139916920504 89.03241525046425\n",
      "\tFPR(%), TPR(%), TNR(%), FNR(%):  0.9360392831259546 9.709260991580916 99.06396071687405 90.29073900841908\n",
      "\tAccuracy(%), Precision(%):  90.01560724458056 53.88992731048806\n",
      "Done.\n",
      "Calculating metrics for sensor: Kuva\n",
      "\tTP, FP, FN, TN:  267398 9048 57178 580518\n",
      "\tTP(%), FP(%), FN(%), TN(%):  29.251254181516657 0.9897805811350971 6.254826930608155 63.50413830674009\n",
      "\tFPR(%), TPR(%), TNR(%), FNR(%):  1.5346882282899625 82.38378684807256 98.46531177171003 17.616213151927436\n",
      "\tAccuracy(%), Precision(%):  92.75539248825675 96.7270280633469\n",
      "Done.\n",
      "Calculating metrics for sensor: Oiler\n",
      "\tTP, FP, FN, TN:  72248 2404 57696 949495\n",
      "\tTP(%), FP(%), FN(%), TN(%):  6.678233348092098 0.22221338955837397 5.333121349400976 87.76643191294855\n",
      "\tFPR(%), TPR(%), TNR(%), FNR(%):  0.25254780181510855 55.59933509819614 99.74745219818489 44.40066490180386\n",
      "\tAccuracy(%), Precision(%):  94.44466526104065 96.77972458875851\n",
      "Done.\n",
      "Calculating metrics for sensor: Qube\n",
      "\tTP, FP, FN, TN:  188323 20255 169929 2768740\n",
      "\tTP(%), FP(%), FN(%), TN(%):  5.98373753315199 0.6435783400540218 5.399290236832381 87.9733938899616\n",
      "\tFPR(%), TPR(%), TNR(%), FNR(%):  0.7262472682812268 52.56718734298762 99.27375273171877 47.43281265701238\n",
      "\tAccuracy(%), Precision(%):  93.9571314231136 90.28900459300597\n",
      "Done.\n",
      "Calculating metrics for sensor: Sensirion\n",
      "\tTP, FP, FN, TN:  333671 92137 38007 3275171\n",
      "\tTP(%), FP(%), FN(%), TN(%):  8.924104021785585 2.464224257592834 1.0165055445513838 87.5951661760702\n",
      "\tFPR(%), TPR(%), TNR(%), FNR(%):  2.7362213376382556 89.77421316300669 97.26377866236174 10.225786836993311\n",
      "\tAccuracy(%), Precision(%):  96.51927019785577 78.36184383571938\n",
      "Done.\n",
      "Calculating metrics for sensor: Soofie\n",
      "\tTP, FP, FN, TN:  182773 201239 29244 2115234\n",
      "\tTP(%), FP(%), FN(%), TN(%):  7.228543518068096 7.958860822071672 1.1565796186656858 83.65601604119455\n",
      "\tFPR(%), TPR(%), TNR(%), FNR(%):  8.687301772997138 86.2067664385403 91.31269822700287 13.793233561459694\n",
      "\tAccuracy(%), Precision(%):  90.88455955926264 47.59564805266502\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# - Total sample size: The number of timestamps in the time-based sequence where GT is not N/A and Pred is not N/A, marked as Ntotal\n",
    "# - TP: The number of timestamps in the time-based sequence where GT is P and Pred is P, marked as NTP\n",
    "# - FP: The number of timestamps in the time-based sequence where GT is N and Pred is P, marked as NFP\n",
    "# - TN: The number of timestamps in the time-based sequence where GT is N and Pred is N, marked as NTN\n",
    "# - FN: The number of timestamps in the time-based sequence where GT is P and Pred is N, marked as NFN\n",
    "# - TP(%): NTP / Ntotal * 100 \n",
    "# - FP(%): NFP / Ntotal * 100 \n",
    "# - FN(%): NFN / Ntotal * 100 \n",
    "# - TN(%): NFN / Ntotal * 100 \n",
    "# - FPR(%): NFP / (NFP +NTN) * 100\n",
    "# - TNR(%): NTN / (NFP +NTN) * 100\n",
    "# - TPR(%): NTP / (NTP +NFN) * 100\n",
    "# - FNR(%): NFN / (NFN +NTP) * 100\n",
    "# - Accuracy(%): (NTP + NTN) / Ntotal * 100\n",
    "# - Precision(%): NTP/(NFP +NTP) * 100\n",
    "\n",
    "metrics_df = pd.DataFrame(columns=[\n",
    "    \"Sensor\",\n",
    "    \"TP(%)\",\n",
    "    \"FP(%)\",\n",
    "    \"FN(%)\",\n",
    "    \"TN(%)\",\n",
    "    \"sample_size\",\n",
    "    \"FPR(%)\",\n",
    "    \"TPR(%)\",\n",
    "    \"TNR(%)\",\n",
    "    \"FNR(%)\",\n",
    "    \"Accuracy(%)\",\n",
    "    \"Precision(%)\"\n",
    "])\n",
    "\n",
    "print(\"Calculating metrics...\")\n",
    "for sn in sensor_names:\n",
    "    print(\"Calculating metrics for sensor: \" + sn)\n",
    "    cur_time_series = combine_time_series[sn]\n",
    "    total_sample_size = ((cur_time_series[\"GT\"] != \"NA\") & (cur_time_series[\"Pred\"] != \"NA\") &\n",
    "                         (pd.notna(cur_time_series[\"GT\"])) & (pd.notna(cur_time_series[\"Pred\"]))\n",
    "                         ).sum()\n",
    "    TP = ((cur_time_series[\"GT\"] == \"P\") & (cur_time_series[\"Pred\"] == \"P\")).sum()\n",
    "    FP = ((cur_time_series[\"GT\"] == \"N\") & (cur_time_series[\"Pred\"] == \"P\")).sum()\n",
    "    FN = ((cur_time_series[\"GT\"] == \"P\") & (cur_time_series[\"Pred\"] == \"N\")).sum()\n",
    "    TN = ((cur_time_series[\"GT\"] == \"N\") & (cur_time_series[\"Pred\"] == \"N\")).sum()\n",
    "\n",
    "    TP_percent = TP / total_sample_size * 100\n",
    "    FP_percent = FP / total_sample_size * 100\n",
    "    FN_percent = FN / total_sample_size * 100\n",
    "    TN_percent = TN / total_sample_size * 100\n",
    "\n",
    "    FPR_percent = FP / (FP + TN) * 100\n",
    "    TNR_percent = TN / (FP + TN) * 100\n",
    "    TPR_percent = TP / (TP + FN) * 100\n",
    "    FNR_percent = FN / (FN + TP) * 100\n",
    "\n",
    "    Accuracy_percent = (TP + TN) / total_sample_size * 100\n",
    "    Precision_percent = TP / (FP + TP) * 100\n",
    "\n",
    "    print(\"\\tTP, FP, FN, TN: \", TP, FP, FN, TN)\n",
    "    print(\"\\tTP(%), FP(%), FN(%), TN(%): \", TP_percent, FP_percent, FN_percent, TN_percent)\n",
    "    print(\"\\tFPR(%), TPR(%), TNR(%), FNR(%): \", FPR_percent, TPR_percent, TNR_percent, FNR_percent)\n",
    "    print(\"\\tAccuracy(%), Precision(%): \", Accuracy_percent, Precision_percent)\n",
    "\n",
    "    metrics_df = metrics_df.append({\n",
    "        \"Sensor\": sn,\n",
    "        \"TP(%)\": \"{}({:.2f})\".format(TP, float(TP_percent)),\n",
    "        \"FP(%)\": \"{}({:.2f})\".format(FP, float(FP_percent)),\n",
    "        \"FN(%)\": \"{}({:.2f})\".format(FN, float(FN_percent)),\n",
    "        \"TN(%)\": \"{}({:.2f})\".format(TN, float(TN_percent)),\n",
    "        \"sample_size\": total_sample_size,\n",
    "        \"FPR(%)\": \"{:.2f}\".format(float(FPR_percent)),\n",
    "        \"TPR(%)\": \"{:.2f}\".format(float(TPR_percent)),\n",
    "        \"TNR(%)\": \"{:.2f}\".format(float(TNR_percent)),\n",
    "        \"FNR(%)\": \"{:.2f}\".format(float(FNR_percent)),\n",
    "        \"Accuracy(%)\": \"{:.2f}\".format(float(Accuracy_percent)),\n",
    "        \"Precision(%)\": \"{:.2f}\".format(float(Precision_percent))\n",
    "    }, ignore_index=True)\n",
    "    print(\"Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving match events for sensor: Andium\tDone.\n",
      "Saving match events for sensor: Canary\tDone.\n",
      "Saving match events for sensor: Ecoteco\tDone.\n",
      "Saving match events for sensor: Kuva\tDone.\n",
      "Saving match events for sensor: Oiler\tDone.\n",
      "Saving match events for sensor: Qube\tDone.\n",
      "Saving match events for sensor: Sensirion\tDone.\n",
      "Saving match events for sensor: Soofie\tDone.\n"
     ]
    }
   ],
   "source": [
    "# Save the metrics to csv file\n",
    "\n",
    "if short_stack:\n",
    "    pre_str = \"ss_\"\n",
    "else:\n",
    "    pre_str = \"\"\n",
    "metrics_df.to_csv(f\"../../results/03_DetectionAnalysis/Time-based ConfusionMatrix/{pre_str}threshold={threshold}xradius_duration={duration}xseconds.csv\", index=False)\n",
    "\n",
    "\n",
    "# Save match events to csv file\n",
    "for sn in sensor_names:\n",
    "    print(\"Saving match events for sensor: \" + sn, end=\"\\t\")\n",
    "    cur_time_series = combine_time_series[sn]\n",
    "    # cur_time_series = cur_time_series[(cur_time_series[\"GT\"] != \"NA\") & (cur_time_series[\"Pred\"] != \"NA\")]\n",
    "    # set norm_class\n",
    "    cur_time_series[\"norm_class\"] = \"NA\"\n",
    "    cur_time_series.loc[(cur_time_series[\"GT\"] == \"P\") & (cur_time_series[\"Pred\"] == \"P\"), \"norm_class\"] = \"TP\"\n",
    "    cur_time_series.loc[(cur_time_series[\"GT\"] == \"N\") & (cur_time_series[\"Pred\"] == \"P\"), \"norm_class\"] = \"FP\"\n",
    "    cur_time_series.loc[(cur_time_series[\"GT\"] == \"P\") & (cur_time_series[\"Pred\"] == \"N\"), \"norm_class\"] = \"FN\"\n",
    "    cur_time_series.loc[(cur_time_series[\"GT\"] == \"N\") & (cur_time_series[\"Pred\"] == \"N\"), \"norm_class\"] = \"TN\"\n",
    "    cur_time_series.to_csv(f\"../../results/03_DetectionAnalysis/Test-case Matching Data/Time-based Events/{pre_str}{threshold}xradius_{duration}xseconds_{sn}_match_events.csv\", index=False)\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot a heatmap for Confusion Matrix\n",
    "\n",
    "In this section, we will use a heatmap to visualize the number of TP/FP/FN/TN for each team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting heatmap for Andium...\n",
      "statics: TP: 191798, FP: 4379, FN: 141025, TN: 2791778\n",
      "Done.\n",
      "Plotting heatmap for Canary...\n",
      "statics: TP: 139394, FP: 19236, FN: 5487, TN: 1190630\n",
      "Done.\n",
      "Plotting heatmap for Ecoteco...\n",
      "statics: TP: 25948, FP: 22202, FN: 241302, TN: 2349707\n",
      "Done.\n",
      "Plotting heatmap for Kuva...\n",
      "statics: TP: 267398, FP: 9048, FN: 57178, TN: 580518\n",
      "Done.\n",
      "Plotting heatmap for Oiler...\n",
      "statics: TP: 72248, FP: 2404, FN: 57696, TN: 949495\n",
      "Done.\n",
      "Plotting heatmap for Qube...\n",
      "statics: TP: 188323, FP: 20255, FN: 169929, TN: 2768740\n",
      "Done.\n",
      "Plotting heatmap for Sensirion...\n",
      "statics: TP: 333671, FP: 92137, FN: 38007, TN: 3275171\n",
      "Done.\n",
      "Plotting heatmap for Soofie...\n",
      "statics: TP: 182773, FP: 201239, FN: 29244, TN: 2115234\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def plot_heatmap(ax, sensor:str, confusion_data: np.ndarray, save_path: PurePath):\n",
    "    \"\"\"\n",
    "    This function plots the confusion matrix heatmap.\n",
    "    :param sensor: sensor name\n",
    "    :param confusion_data: confusion matrix data, a numpy array of shape (2, 2)\n",
    "    :param save_path: save path\n",
    "    \"\"\"\n",
    "\n",
    "    plt.imshow(confusion_data, cmap=plt.cm.Oranges, interpolation='nearest')\n",
    "    plt.title(\"Confusion Matrix for {}\".format(sensor), fontsize=16)\n",
    "    plt.xlabel(\"Released\", fontsize=14)\n",
    "    plt.ylabel(\"Reported\", fontsize=14)\n",
    "\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Add x and y ticks\n",
    "    plt.xticks([0, 1], [\"Positive\", \"Negative\"], fontsize=12)\n",
    "    plt.yticks([0, 1], [\"Positive\", \"Negative\"], fontsize=12)\n",
    "\n",
    "    classifier = [[\"TP\", \"FP\"], [\"FN\", \"TN\"]]\n",
    "    rates = confusion_data / confusion_data.sum()\n",
    "\n",
    "    # Add text annotations\n",
    "    for i in range(confusion_data.shape[0]):\n",
    "        for j in range(confusion_data.shape[1]):\n",
    "            plt.text(j, i, \n",
    "                    \"{}\\n\".format(classifier[i][j]) +\n",
    "                    format(confusion_data[i, j], \",\") + \"\\n\" +\n",
    "                    \"{:.2f}%\".format(rates[i, j] * 100),\n",
    "                     ha=\"center\", va=\"center\", color=\"black\", fontsize=12)\n",
    "    \n",
    "    # Save the confusion matrix heatmap\n",
    "    plt.savefig(save_path, dpi=300, box_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "save_dir = PurePath(\"../../results/03_DetectionAnalysis/Test-case Matching Data/Time-based Events/Heatmap/\")\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "\n",
    "for i in range(metrics_df.shape[0]):\n",
    "    sn = metrics_df.loc[i, \"Sensor\"]\n",
    "    save_path = PurePath(save_dir, f\"./{pre_str}{threshold}xradius_{duration}xseconds_{sn}_heatmap.jpg\")\n",
    "    sensor_name = metrics_df.loc[i, \"Sensor\"]\n",
    "    print(\"Plotting heatmap for {}...\".format(sensor_name))\n",
    "\n",
    "    TP = metrics_df.loc[i, \"TP(%)\"].split(\"(\")[0]\n",
    "    FP = metrics_df.loc[i, \"FP(%)\"].split(\"(\")[0]\n",
    "    FN = metrics_df.loc[i, \"FN(%)\"].split(\"(\")[0]\n",
    "    TN = metrics_df.loc[i, \"TN(%)\"].split(\"(\")[0]\n",
    "    print(\"statics: TP: {}, FP: {}, FN: {}, TN: {}\".format(TP, FP, FN, TN))\n",
    "\n",
    "    confusion_data = np.array([[int(TP), int(FP)], [int(FN), int(TN)]])\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    plot_heatmap(ax, sensor_name, confusion_data, save_path)\n",
    "    print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
