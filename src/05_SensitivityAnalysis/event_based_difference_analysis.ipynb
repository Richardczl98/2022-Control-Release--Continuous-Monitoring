{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from pathlib import PurePath\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the parameter space\n",
    "\n",
    "- threshold: [1, 2, 4] (representing 1/2/4 times the experimental area radius for wind transpose model)\n",
    "- ignore_duration: [30, 60, 120] (indicating event lengths below 30/60/120 seconds to be ignored)\n",
    "- short_stack: [0, 1] (0 for analyzing all experimental dates, 1 for analyzing only the short stack scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Parameters:\n",
      "Threshold            Ignore Duration      Short Stack         \n",
      "1                    60                   0                   \n",
      "2                    60                   0                   \n",
      "4                    60                   0                   \n"
     ]
    }
   ],
   "source": [
    "threshold = [1, 2, 4]\n",
    "ignore_duration = [30, 60, 120]\n",
    "short_stack = [0, 1]\n",
    "\n",
    "inputs = [\n",
    "    [1, 60, 0],\n",
    "    [2, 60, 0],\n",
    "    [4, 60, 0]\n",
    "]\n",
    "\n",
    "print(\"Input Parameters:\")\n",
    "print(\"{:<20} {:<20} {:<20}\".format('Threshold', 'Ignore Duration', 'Short Stack'))\n",
    "for i in inputs:\n",
    "    print(\"{:<20} {:<20} {:<20}\".format(i[0], i[1], i[2]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Confusion Matrix for Reliability metrics\n",
    "\n",
    "For bellow inputs, load the data for the Event-based Confusion Matrix for metrics \n",
    "                                                                \"Detection Rate (%)\",\n",
    "                                                                \"Non-Emission Accuracy (%)\",\n",
    "                                                                \"Reliability of Identifications (%)\",\n",
    "                                                                \"Reliability of Non-Emission Identifications (%)\"\n",
    "| threshold | ignore_duration | short_stack |\n",
    "| :-: | :-: | :-: |\n",
    "| 1 | 60 | 0 | \n",
    "| 2 | 60 | 0 |\n",
    "| 4 | 60 | 0 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading metrics data...\n",
      "\tcurrent parameter: threshold = 1, ignore_duration = 60, short_stack = 0\n",
      "\t\tcurrent sensor: Andium\n",
      "\t\tcurrent sensor: Canary\n",
      "\t\tcurrent sensor: Ecoteco\n",
      "\t\tcurrent sensor: Kuva\n",
      "\t\tcurrent sensor: Oiler\n",
      "\t\tcurrent sensor: Qube\n",
      "\t\tcurrent sensor: Sensirion\n",
      "\tcurrent parameter: threshold = 2, ignore_duration = 60, short_stack = 0\n",
      "\t\tcurrent sensor: Andium\n",
      "\t\tcurrent sensor: Canary\n",
      "\t\tcurrent sensor: Ecoteco\n",
      "\t\tcurrent sensor: Kuva\n",
      "\t\tcurrent sensor: Oiler\n",
      "\t\tcurrent sensor: Qube\n",
      "\t\tcurrent sensor: Sensirion\n",
      "\tcurrent parameter: threshold = 4, ignore_duration = 60, short_stack = 0\n",
      "\t\tcurrent sensor: Andium\n",
      "\t\tcurrent sensor: Canary\n",
      "\t\tcurrent sensor: Ecoteco\n",
      "\t\tcurrent sensor: Kuva\n",
      "\t\tcurrent sensor: Oiler\n",
      "\t\tcurrent sensor: Qube\n",
      "\t\tcurrent sensor: Sensirion\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# set the path of all confusion matrix data\n",
    "data_dir_stanford_defined = PurePath(\"../../results/03_DetectionAnalysis/Event-based ConfusionMatrix/Stanford Defined Events_Reliability/\")\n",
    "data_dir_team_defined = PurePath(\"../../results/03_DetectionAnalysis/Event-based ConfusionMatrix/Team Defined Events_Reliability/\")\n",
    "path_pattern = \"threshold={}xradius_duration={}xseconds.csv\"\n",
    "\n",
    "# set the path of all event-based difference data\n",
    "save_path = PurePath(\"../../results/05_SensitivityAnalysis/Event-based Difference Analysis/\")\n",
    "save_pattern = \"{}_difference.csv\"\n",
    "\n",
    "\n",
    "# set sensor names\n",
    "sensor_names = [\"Andium\", \"Canary\", \"Ecoteco\", \"Kuva\", \"Oiler\", \"Qube\", \"Sensirion\"]\n",
    "\n",
    "\n",
    "def get_number_of_events_for_stanford(sensor_name, threshold, ignore_duration, short_stack, is_team_defined=False):\n",
    "    \"\"\"\n",
    "    This function is used to get the number of events for a sensor.\n",
    "    Args:\n",
    "        sensor_name: the name of a sensor\n",
    "        threshold: the threshold of a sensor\n",
    "        ignore_duration: the ignore duration of a sensor\n",
    "        short_stack: the short stack of a sensor\n",
    "    Returns:\n",
    "        number_of_events: the number of events for a sensor\n",
    "    \"\"\"\n",
    "    if short_stack:\n",
    "        pre_str = \"ss_\"\n",
    "    else:\n",
    "        pre_str = \"\"\n",
    "\n",
    "    if is_team_defined:\n",
    "        match_events_save_pattern = PurePath(\n",
    "            \"../../results/03_DetectionAnalysis/Test-case Matching Data/Team Defined Events/\",\n",
    "            \"{}{}xradius_{}xseconds_{}_match_events.csv\".format(\n",
    "                pre_str, threshold, ignore_duration, sensor_name\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        match_events_save_pattern = PurePath(\n",
    "            \"../../results/03_DetectionAnalysis/Test-case Matching Data/Stanford Defined Events/\",\n",
    "            \"{}{}xradius_{}xseconds_{}_match_events.csv\".format(\n",
    "                pre_str, threshold, ignore_duration, sensor_name\n",
    "            )\n",
    "        )\n",
    "    df_match_events = pd.read_csv(match_events_save_pattern)\n",
    "    df_match_events.dropna(inplace=True)\n",
    "    df_match_events.reset_index(drop=True, inplace=True)\n",
    "    number_of_events = df_match_events.shape[0]\n",
    "\n",
    "    return number_of_events\n",
    "\n",
    "def get_event_based_difference_for_Reliability(data_dir, path_pattern, inputs, sensor_names):\n",
    "    \"\"\"\n",
    "    This function is used to get the event-based difference between Stanford Defined Events and Team Defined Events.\n",
    "    Args:\n",
    "        data_dir: the directory of all confusion matrix data\n",
    "        path_pattern: the pattern of all confusion matrix data\n",
    "        inputs: the list of all inputs\n",
    "        sensor_names: the list of all sensor names\n",
    "    Returns:\n",
    "        difference_dict: the dictionary of all event-based difference data\n",
    "    \"\"\"\n",
    "\n",
    "    difference_dict = {}\n",
    "    for sensor_name in sensor_names:\n",
    "        difference_dict[sensor_name] = pd.DataFrame(columns=[\"threshold\", \n",
    "                                                                \"Detection Rate (%)\",\n",
    "                                                                \"Non-Emission Accuracy (%)\",\n",
    "                                                                \"Reliability of Identifications (%)\",\n",
    "                                                                \"Reliability of Non-Emission Identifications (%)\"\n",
    "                                                             ])\n",
    "\n",
    "    for input in inputs:\n",
    "        threshold = input[0]\n",
    "        ignore_duration = input[1]\n",
    "        short_stack = input[2]\n",
    "        print(\"\\tcurrent parameter: threshold = {}, ignore_duration = {}, short_stack = {}\".format(threshold, ignore_duration, short_stack))\n",
    "\n",
    "        # set the path of all confusion matrix data\n",
    "        if short_stack == 0:\n",
    "            prev_save_str = \"\"\n",
    "        else:\n",
    "            prev_save_str = \"ss_\"\n",
    "\n",
    "        # set the path of all event-based confusion matrix data\n",
    "        data_path_stanford_defined = PurePath(data_dir[0], prev_save_str + path_pattern.format(threshold, ignore_duration))\n",
    "        data_path_team_defined = PurePath(data_dir[1], prev_save_str + path_pattern.format(threshold, ignore_duration))\n",
    "\n",
    "        # load data\n",
    "        df_stanford_defined = pd.read_csv(data_path_stanford_defined, index_col=0)\n",
    "        df_team_defined = pd.read_csv(data_path_team_defined, index_col=0)\n",
    "        for sensor_name in sensor_names:\n",
    "            # calculate TPR and FNR for Stanford Defined Events\n",
    "            print(\"\\t\\tcurrent sensor: {}\".format(sensor_name))\n",
    "            DR = df_stanford_defined.loc[df_stanford_defined.index == sensor_name, \"Detection Rate (%)\"] \n",
    "            NEA = df_stanford_defined.loc[df_stanford_defined.index == sensor_name, \"Non-Emission Accuracy (%)\"]\n",
    "\n",
    "            # calculate TPR and FNR for Team Defined Events\n",
    "            RoI = df_team_defined.loc[df_team_defined.index == sensor_name, \"Reliability of Identifications (%)\"]\n",
    "            RoNEI = df_team_defined.loc[df_team_defined.index == sensor_name, \"Reliability of Non-Emission Identifications (%)\"]\n",
    "\n",
    "            number_of_stanford_defined_events = get_number_of_events_for_stanford(sensor_name, threshold, ignore_duration, short_stack)\n",
    "            number_of_team_defined_events = get_number_of_events_for_stanford(sensor_name, threshold, ignore_duration, short_stack, True)\n",
    "\n",
    "\n",
    "            # add data to the dataframe\n",
    "            difference_dict[sensor_name] = difference_dict[sensor_name].append({\"threshold\": threshold,\n",
    "                                                                                \"Number of Stanford Defined Events\": number_of_stanford_defined_events,\n",
    "                                                                                \"Number of Team Defined Events\": number_of_team_defined_events,\n",
    "                                                                                \"Detection Rate (%)\": float(\"{:.2f}\".format(DR.values[0])),\n",
    "                                                                                \"Non-Emission Accuracy (%)\": float(\"{:.2f}\".format(NEA.values[0])),\n",
    "                                                                                \"Reliability of Identifications (%)\": float(\"{:.2f}\".format(RoI.values[0])),\n",
    "                                                                                \"Reliability of Non-Emission Identifications (%)\": float(\"{:.2f}\".format(RoNEI.values[0]))\n",
    "                                                                                }, ignore_index=True)\n",
    "        \n",
    "        # set type of threshold and ignore_duration, short_stack\n",
    "        for sensor_name in sensor_names:\n",
    "            difference_dict[sensor_name][\"threshold\"] = difference_dict[sensor_name][\"threshold\"].astype(int)\n",
    "            difference_dict[sensor_name][\"Number of Stanford Defined Events\"] = difference_dict[sensor_name][\"Number of Stanford Defined Events\"].astype(int)\n",
    "            difference_dict[sensor_name][\"Number of Team Defined Events\"] = difference_dict[sensor_name][\"Number of Team Defined Events\"].astype(int)\n",
    "        \n",
    "        # reorder columns\n",
    "        for sensor_name in sensor_names:\n",
    "            difference_dict[sensor_name] = difference_dict[sensor_name][[\"threshold\", \n",
    "                                                                        \"Number of Stanford Defined Events\",\n",
    "                                                                        \"Number of Team Defined Events\",\n",
    "                                                                        \"Detection Rate (%)\",\n",
    "                                                                        \"Non-Emission Accuracy (%)\",\n",
    "                                                                        \"Reliability of Identifications (%)\",\n",
    "                                                                        \"Reliability of Non-Emission Identifications (%)\"\n",
    "                                                                        ]]\n",
    "    return difference_dict\n",
    "\n",
    "print(\"Reading metrics data...\")\n",
    "difference_dict = get_event_based_difference_for_Reliability([data_dir_stanford_defined, data_dir_team_defined], path_pattern, inputs, sensor_names)\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all sensors\n",
    "\n",
    "save_columns = [\n",
    "    \"sensor\",\n",
    "    \"threshold\", \n",
    "    \"Number of Stanford Defined Events\",\n",
    "    \"Number of Team Defined Events\",\n",
    "    \"Detection Rate (%)\",\n",
    "    \"Non-Emission Accuracy (%)\",\n",
    "    \"Reliability of Identifications (%)\",\n",
    "    \"Reliability of Non-Emission Identifications (%)\"\n",
    "            ]\n",
    "save_df = pd.DataFrame(columns=save_columns)\n",
    "n = 0\n",
    "for sensor_name in sensor_names:\n",
    "\n",
    "    cur_df = difference_dict[sensor_name]\n",
    "    for i in range(cur_df.shape[0]):\n",
    "        save_df.loc[n, save_columns] = [sensor_name] + cur_df.loc[i, :].tolist()\n",
    "        n += 1\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "save_df[\"threshold\"] = save_df[\"threshold\"].astype(int)\n",
    "save_df[\"Number of Stanford Defined Events\"] = save_df[\"Number of Stanford Defined Events\"].astype(int)\n",
    "save_df[\"Number of Team Defined Events\"] = save_df[\"Number of Team Defined Events\"].astype(int)\n",
    "save_df.to_csv(PurePath(save_path, \"event_based_results.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
